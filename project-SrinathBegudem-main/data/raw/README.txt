
The get_data.py script is designed to selectively scrape a limited subset of the full dataset, specifically targeting only a couple of pages. This design decision is made to minimize the processing time, allowing users to quickly validate the scraping functionality without waiting for the extensive completion time associated with scraping all 226 pages, which can take up to 5-6 hours. This script serves as a practical demonstration of the scraping capabilities, providing a snapshot of the process with a manageable subset of the data for evaluation purposes. The complete dataset, which has been fully scraped and cleaned, resides in the main data folder within the 'processed' directory, ensuring that comprehensive data is available for in-depth analysis while maintaining usability and efficiency in demonstration scenarios.
